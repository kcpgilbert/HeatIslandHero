{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a7e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63983ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Keras utils\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Dense, Normalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f518f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the text file\n",
    "county_names = []\n",
    "with open('counties.txt','r') as file:\n",
    "    # reading each line   \n",
    "    for line in file:   \n",
    "        county_names += [line.replace('\\n','')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7bbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse historic data as inputs\n",
    "for i in range(len(county_names)):\n",
    "    dataset_name = \"data/CHAT-\"+str(county_names[i])+\"-historical.csv\"\n",
    "    if i == 0:\n",
    "        pd_data_historic = pd.read_csv(dataset_name)\n",
    "    else:\n",
    "        pd_data_remain = pd.read_csv(dataset_name)\n",
    "        pd_data_historic = pd.concat([pd_data_historic,pd_data_remain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bbe3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse UHII values\n",
    "for i in range(len(county_names)):\n",
    "    dataset_name = \"data/CHAT-\"+str(county_names[i])+\"-vulnerability-indicators.csv\"\n",
    "    if i == 0:\n",
    "        pd_data_uhii_base = pd.read_csv(dataset_name)\n",
    "        pd_data_uhii = pd_data_uhii_base \n",
    "        for j in range(4):\n",
    "            pd_data_uhii = pd.concat([pd_data_uhii,pd_data_uhii_base])  \n",
    "  \n",
    "    else:\n",
    "        pd_data_remain_base = pd.read_csv(dataset_name)\n",
    "        pd_data_remain = pd_data_remain_base\n",
    "        for j in range(4):\n",
    "            pd_data_remain = pd.concat([pd_data_remain,pd_data_remain_base])\n",
    "        pd_data_uhii = pd.concat([pd_data_uhii,pd_data_remain])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0648e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd_data_historic[['time_of_year', 'socioeconomic_group','avg_event_rh_max_perc','avg_event_rh_min_perc','tmax','tmin','hist_avg_annual_events','hist_avg_duration']]\n",
    "y = pd_data_uhii[[\"uhii_avgdeltat\"]].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43432ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NGulgec\\AppData\\Local\\Temp\\ipykernel_17708\\1102404862.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_all[\"time_of_year\"] = X_all[\"time_of_year\"].replace({\n",
      "C:\\Users\\NGulgec\\AppData\\Local\\Temp\\ipykernel_17708\\1102404862.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_all[\"socioeconomic_group\"] = X_all[\"socioeconomic_group\"].replace({\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for inputs and outputs\n",
    "X_all[\"time_of_year\"] = X_all[\"time_of_year\"].replace({\n",
    "    \"Total\": 0,\n",
    "    \"AM\": 1,\n",
    "    \"JJA\": 2,\n",
    "    \"SO\": 3})\n",
    "\n",
    "X_all[\"socioeconomic_group\"] = X_all[\"socioeconomic_group\"].replace({\n",
    "    \"2006 HW\": 0,\n",
    "    \"Vulnerable\": 1,\n",
    "    \"General\": 2\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9dff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we are having reproducable results\n",
    "import random as python_random\n",
    "np.random.seed(12345)\n",
    "python_random.seed(12345)\n",
    "tf.random.set_seed(12345)\n",
    "\n",
    "# Split the dataset\n",
    "randomseed = 12345\n",
    "indx_bin=np.arange(0,len(y))\n",
    "random.Random(randomseed).shuffle(indx_bin)\n",
    "\n",
    "train_split=0.6\n",
    "val_split=0.2\n",
    "test_split=0.2\n",
    "\n",
    "nTrain=int(train_split*len(indx_bin))\n",
    "nVal=int(val_split*len(indx_bin))\n",
    "nTest=int(test_split*len(indx_bin))\n",
    "train_indx_bin=indx_bin[0:nTrain]\n",
    "val_indx_bin=indx_bin[nTrain:nTrain+nVal]\n",
    "test_indx_bin=indx_bin[nTrain+nVal:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4177d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24123, 8)\n",
      "(24123, 1)\n",
      "(8041, 8)\n",
      "(8041, 1)\n",
      "(8041, 8)\n",
      "(8041, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train=X_all.values[train_indx_bin]\n",
    "y_train=y.values[train_indx_bin]\n",
    "X_val=X_all.values[val_indx_bin]\n",
    "y_val=y.values[val_indx_bin]\n",
    "X_test=X_all.values[test_indx_bin]\n",
    "y_test=y.values[test_indx_bin]\n",
    "\n",
    "standardize=True\n",
    "\n",
    "# Apply normalization to the training dataset\n",
    "if standardize:\n",
    "    normalize_layer = Normalization()\n",
    "    normalize_layer.adapt(X_train)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0efbc73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_name = 'model_3'\n",
    "model = keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b44d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754/754 [==============================] - 2s 2ms/step\n",
      "252/252 [==============================] - 1s 2ms/step\n",
      "Section accuracy on validation data: 87.45 (%)\n",
      "252/252 [==============================] - 1s 2ms/step\n",
      "Section accuracy on testing data: 88.17 (%)\n"
     ]
    }
   ],
   "source": [
    "# Print section accuracies\n",
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "#print('Section accuracy on training data: %1.2f (%%)'%(scores[1]*100))    \n",
    "\n",
    "pred_val= model.predict(X_val)\n",
    "scores2 = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Section accuracy on validation data: %1.2f (%%)'%(scores2[1]*100)) \n",
    "\n",
    "pred_test= model.predict(X_test)\n",
    "scores3 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Section accuracy on testing data: %1.2f (%%)'%(scores3[1]*100))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
